<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.49" />


<title>[Spanish] Análisis de variables numéricas, parte 1. - Diego Halabi</title>
<meta property="og:title" content="[Spanish] Análisis de variables numéricas, parte 1. - Diego Halabi">



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Dh">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/diegohalabi">GitHub</a></li>
    
    <li><a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Halabi&#43;D%5BAuthor%5D&#43;&#43;AND&#43;Austral">Publications</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">8 min read</span>
    

    <h1 class="article-title">[Spanish] Análisis de variables numéricas, parte 1.</h1>

    
    <span class="article-date">2018/10/06</span>
    

    <div class="article-content">
      <div id="introduccion." class="section level1">
<h1><span class="header-section-number">1</span> Introducción.</h1>
<p>Una de las situaciones más comunes en investigación de ciencias médicas, es medir una variable numérica que se separa entre 2 o más grupos. Por ejemplo, en una investigación podría comparar cómo mejora la presión arterial entre pacientes sometidos a 2 tratamientos diferentes, o evaluar la producción una proteína en células expuestas a distintas dosis de un fármaco.</p>
<p>En estos casos, nos interesa saber si el promedio y/o la dispersión de la variable es diferente entre los grupos.</p>
<div class="figure">
<img src="/post/2018-10-05-analisis-de-variables-cuantitativas_files/algoritmo.png" alt="Figura 1. Algoritmo para escoger el test estadístico más adecuado cuando trabaja con variables numéricas." width="700" />
<p class="caption">Figura 1. Algoritmo para escoger el test estadístico más adecuado cuando trabaja con variables numéricas.</p>
</div>
<p>Sin embargo, antes de hacer estas comparaciones necesitamos evaluar algunos aspectos de los datos, como su distribución, la cantidad de grupos o la dependencia de estos grupos. La figura 1 es el algoritmo para analizar datos cuantitativos, cuando éstos se separan en 2 o más grupos.</p>
<p>En este artículo nos centraremos en la distribución normal y la comparación de variables numéricas entre 2 grupos. En una siguiente entrada, continuaremos con los análisis que comparan variables numéricas ente más de grupos, y algunos aspectos de machine learning supervisado.</p>
</div>
<div id="distribucion-normal." class="section level1">
<h1><span class="header-section-number">2</span> Distribución normal.</h1>
<p>La distribución normal es la forma en que los datos se agrupan en la naturaleza, cuando han sido evaluados en forma aleatoria y, por lo tanto, representativa. Cuando los datos se ajustan a esta distribución, se le llama una muestra <strong>paramétrica</strong>.</p>
<p>Es fundamental evaluar si nuestros datos se ajustan a esta distribución, ya que muchos test estadísticos requieren que la muestra sea paramétrica. En caso que no se ajusten, podemos elegir un test no paramétrico, o bien, normalizar los datos.</p>
<p>Una forma sencilla de entender la distribución normal, es imaginar la estatura en una sala con 100 estudiantes. La mayoría de ellos tendrá una estatura promedio, por lo que podríamos agrupar una gran frecuencia de estudiantes que miden 1.70 m en el centro de la distribución. A medida que la estatura aumenta, la frecuencia de estudiantes va disminuyendo, de la misma forma que en las estaturas más bajas.</p>
<p><img src="/post/2018-10-05-analisis-de-variables-cuantitativas_files/figure-html/unnamed-chunk-2-1.png" width="336" /></p>
<p>En la figura 2, podemos observar que la distribución normal tiene algunas características que la definen:</p>
<ol style="list-style-type: decimal">
<li>Una gran cantidad de datos agrupados al centro, y pocos en los extremos.</li>
<li>La línea roja muestra el promedio (1.70 m), y coincide con la mediana. Ergo, su forma es simétrica.</li>
<li>Debe tener un número mínimo para lograr su formarse, aproximadamente &gt; 15 observaciones.</li>
</ol>
<p>Para poder evaluar el ajuste de nuestros datos a la distribución normal, disponemos de muchas herramientas, por lo que nos centraremos en la visualización gráfica, el test de Shapiro Wilk, el test D’agostino Pearson Omnibus, y la representación gráfica de cuantil-cuantil.</p>
<div id="shapiro-wilk." class="section level2">
<h2><span class="header-section-number">2.1</span> Shapiro Wilk.</h2>
<p>Para realizar este test, se calcula el promedio y la varianza de la muestra, y se ordenan todos los datos de menor a mayor. Luego, se compara la diferencia que existe entre el primero y el último, el segundo y el penúltimo. etc. De esta forma, análisis determina un estadístico W, que se extrapola a un p-value <span class="citation">(<a href="#ref-Shapiro:1965gf">1</a>)</span>.</p>
<p>La hipótesis nula es que los datos se ajustan a la distribución normal, por lo que podemos asumir la normalidad de nuestros datos con un p-value mayor que alfa (p &gt; 0.05).</p>
</div>
<div id="dagostino-pearson-omnibus." class="section level2">
<h2><span class="header-section-number">2.2</span> D’agostino Pearson Omnibus.</h2>
<p>El test de Shapiro Wilk es muy útil cuando el tamaño muestral es menor que 50, sin embargo, no es capaz de identificar la normalidad en muestras que superen este tamaño. Para resolver este problema, en el año 1971 se creó el test D’agostino Pearson Omnibus <span class="citation">(<a href="#ref-DAgostino:1971ia">2</a>)</span>.</p>
<p>Este test estima un estadístico D, que se calcula a partir de la asimetría de la muestra y su curtosis.</p>
<p>Al igual que en Shapir-Wilk, el estadístico D se puede extrapolar a un p-value, que se interpreta de la misma forma (hipótesis nula es ajuste a la normalidad).</p>
</div>
<div id="grafico-cuantil-cuantil-q-q-plot." class="section level2">
<h2><span class="header-section-number">2.3</span> Gráfico cuantil-cuantil (Q-Q plot).</h2>
<p>Finalmente, podemos evaluar la normalidad en forma visual con el Q-Q plot. Este gráfico compara los cuantiles de una muestra real con los cuantiles teóricos de una distribución de probabilidad.</p>
<p>Si recordamos, un cuantil es una división en partes iguales de un set de datos. Por ejemplo, si tenemos 100 observaciones entre 1.6 m y 1.8 m, los cuantiles teóricos se formarán dividiendo en 100 partes iguales el rango 1.6 - 1.8, obteniendo 100 cuantiles de 0.2 m en el eje Y. Estos cuantiles teóricos se comparan con las 100 observaciones reales en nuestro set de datos, obteniendo una correlación (fig 3).</p>
<p><img src="/post/2018-10-05-analisis-de-variables-cuantitativas_files/figure-html/unnamed-chunk-3-1.png" width="336" /></p>
<p>Si utilizamos R (recomendado), la función <code>'qqpnorm()'</code> permite crear fácilmente este gráfico. En la figura 3, se han utilizado los mismos datos que en la figura 2, y se visualiza directamente como las observaciones (puntos) se ajustan a la curva teórica (línea roja), lo que sugiere normalidad.</p>
</div>
</div>
<div id="comparando-2-medias." class="section level1">
<h1><span class="header-section-number">3</span> Comparando 2 medias.</h1>
<p>Una situación muy común en investigación, es medir una variable numérica separada en 2 grupos. Entonces, la estadística nos ayudará a responder si las diferencias que observamos en el promedio (o mediana) se deben al azar, o bien, si podemos extrapolarlas a la población.</p>
<p>En el ejemplo de la figura 4, se observan los resultados en la producción de insulina de cultivos de hepatocitos, que provienen de ratones hipertensos y controles (2 grupos).</p>
<p><img src="/post/2018-10-05-analisis-de-variables-cuantitativas_files/figure-html/unnamed-chunk-4-1.png" width="288" /></p>
<p>¿Producen más insluina los ratones controles? ¿Es significativa esa diferencia?</p>
<div id="t-test-independiente." class="section level2">
<h2><span class="header-section-number">3.1</span> t-test independiente.</h2>
<p>Permite identificar si el promedio y las desviaciones estándar de 2 grupos difieren significativamente.</p>
<p>Antes de realizar un t-test, se debe considerar si se cumple con los supuestos o <em>assumptions</em> <span class="citation">(<a href="#ref-Student:1908fk">3</a>)</span>:</p>
<ul>
<li><p>Requiere que los grupos sean independientes, es decir, que una observación no dependa de otras observaciones. Esto se logra utilizando una correcta técnica de muestreo aleatorio.</p></li>
<li><p>La muestra debe ser paramétrica, es decir, debe obtenerse a partir de una distribución normal. Este assumption puede ser obviado cuando se trabaja con un tamaño muestral &gt; 15 por grupo, ya que si realizamos un test no paramétrico llegaríamos a resultados extremadamente similares.</p></li>
<li><p>Igualdad de varianzas u homocedasticidad. Podemos evaluarlo de manera visual, o con el test de Levene, cuya H<sub>0</sub> es que las varianzas son homogéneas. Este test se aplica con la función <code>'leveneTest()'</code> del paquete <code>'car'</code>.</p></li>
</ul>
<p>En R, podemos realizar el t-test con la función <code>'t.test()'</code>, y si lo aplicamos al ejemplo anterior tendríamos el siguiente output:</p>
<pre><code>## 
##  Two Sample t-test
## 
## data:  insulina by grupo
## t = -5.2633, df = 98, p-value = 8.349e-07
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -6.029237 -2.727593
## sample estimates:
##     mean in group HTA mean in group Control 
##              9.290493             13.668908</code></pre>
<p>Podemos ver que el p-value es &lt; 0.001, por lo que rechazaríamos la H<sub>0</sub>. Además, podemos obtener resultados de interés clínico-fisiológico (tamaño del efecto), como el promedio de los grupos y el intervalo de confianza al 95% de la diferencia de medias.</p>
</div>
<div id="t-test-pareado." class="section level2">
<h2><span class="header-section-number">3.2</span> t-test pareado.</h2>
<p>Existen casos que el diseño experimental requiere que las muestras sean dependientes, entonces se puede optar por un t-test pareado o dependiente. Estos diseños nos permiten controlar muy bien las variables confundentes y covariables, al permitir emparejar uno o más factores entre los distintos grupos experimentales y controles.</p>
<p>Un ejemplo clásico es en estudios de odontología, donde se utiliza el diseño de “boca dividida”. Es este diseño, se divide la arcada dental sagitalmente en un lado derecho y otro izquierdo, exponiendo al paciente al tratamiento y control en cada lado. Es evidente que todos los factores se van a repetir entre los 2 lados, por lo que se considera que los grupos están pareados o son dependientes entre si.</p>
<p>Otros ejemplos son los Ensayos Clínicos Aleatorios de diseño cruzado, en que los mismos participantes del grupo experimental se intercambian al grupo control, o los estudios de cohorte emparejados por factores de riesgo. En el laboratorio también se realizan muchos diseños pareados, por ejemplo, si un cultivo celular separado a distintos tratamientos proviene de una misma fuente primaria, o en animales que son emparejados por ser de la misma camada.</p>
<p>En R, lo utilizamos agregando el argumento <code>'paired = True'</code> a la función <code>'t.test()'</code>.</p>
</div>
<div id="u-mann-whitney-wilcoxon-test." class="section level2">
<h2><span class="header-section-number">3.3</span> U Mann-Whitney – Wilcoxon test.</h2>
<p>En los casos que no se cumpla el supuesto de normalidad, podemos reemplazar el t-test por el U Mann-Whitney en las muestras con observaciones independientes <span class="citation">(<a href="#ref-Mann:1947jp">4</a>)</span>, o Wilcoxon para muestras pareadas <span class="citation">(<a href="#ref-Wilcoxon:1945kw">5</a>)</span>.</p>
<p>Ambos test son muy simples de entender, básicamente ordenan todos los datos de ambos grupos en un ranking. Si los datos provienen de la misma población, se intercalarán los valores consecutivamente, ergo aceptaríamos la H<sub>0</sub>. Si provienen de poblaciones distintas, los valores de los grupos quedarán separados, por lo que debería asumir que los grupos difieren significativamente, rechazando la H<sub>0</sub> (fig 5).</p>
<p><img src="/post/2018-10-05-analisis-de-variables-cuantitativas_files/figure-html/unnamed-chunk-6-1.png" width="384" /></p>
<p>Ambos test se pueden aplicar en R con la función <code>'wilcox.test()'</code>, agregando el parámetro <code>'paired = TRUE'</code> o <code>'paired = FALSE'</code> para realizar el test U Mann-Whitney o Wilcoxon respectivamente.</p>
</div>
</div>
<div id="referencias" class="section level1 unnumbered">
<h1>Referencias</h1>
<div id="refs" class="references">
<div id="ref-Shapiro:1965gf">
<p>1. Shapiro SS, Wilk MB. An Analysis of Variance Test for Normality (Complete Samples). Biometrika. 1965 Dec;52(3/4):591–22. </p>
</div>
<div id="ref-DAgostino:1971ia">
<p>2. D’Agostino RB. An Omnibus Test of Normality for Moderate and Large Size Samples. Biometrika. 1971 Aug;58(2):341–9. </p>
</div>
<div id="ref-Student:1908fk">
<p>3. Student. The Probable Error of a Mean. Biometrika. 1908 Mar;6(1):1. </p>
</div>
<div id="ref-Mann:1947jp">
<p>4. Mann HB, Whitney DR. On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other. The Annals of Mathematical Statistics. 1947 Mar;18(1):50–60. </p>
</div>
<div id="ref-Wilcoxon:1945kw">
<p>5. Wilcoxon F. Individual Comparisons by Ranking Methods. Biometrics Bulletin. 1945 Dec;1(6):80. </p>
</div>
</div>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//diegohalabi-github-io.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



      <footer class="footer">
        <ul class="footer-links">
          <li> 
            <a href="https://www.twitter.com/diegohalabi" class="footer-links-kudos"> <img src="/images/twitter.svg" alt="Twitter" width="16" height="16"></a>
            <a href="https://www.github.com/diegohalabi" class="footer-links-kudos"> <img src="/images/github.svg" alt="Github" width="16" height="16" ></a>
            <a href="https://www.researchgate.net/profile/Diego_Halabi" class="footer-links-kudos"> <img src="/images/rg.png" alt="Researchgate" width="16" height="16"></a>
            <a href="mailto:diego.halabi@uach.cl" class="footer-links-kudos"> <img src="/images/mail.svg" alt="E-mail" width="16" height="16"></a>
          </li>
          <br>
          <font size="2">Devloped by Diego Halabi</font>
          <br>
          <font size="2">© Text and Code<a href="https://www.gnu.org/licenses/gpl-3.0.html">GPL v3</a>unless otherwise specified.</font>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-127564436-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

